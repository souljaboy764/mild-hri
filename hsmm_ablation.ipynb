{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Human VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "import pbdlib as pbd\n",
    "\n",
    "import networks\n",
    "import config\n",
    "from utils import *\n",
    "import dataloaders\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model | Z Dim | MSE | Recon |\n",
      "|:-----:|:-----:|:----:|:----:|\n",
      "| ablation_vae | 3 | 8.3238e-01 ± 1.2583e+00 | 2.5362e-01 ± 2.2689e-01 |\n",
      "| vae_crosskl | 3 | 8.3685e-01 ± 1.2672e+00 | 3.0193e-01 ± 2.3822e-01 |\n",
      "| vae_onlycrosskl | 3 | 8.4034e-01 ± 1.3129e+00 | 2.4277e-01 ± 2.2238e-01 |\n",
      "| vae_sophia_onlycrosskl | 3 | 8.2272e-01 ± 1.3904e+00 | 1.8425e-01 ± 1.7161e-01 |\n",
      "| vae_sophia_addcrosskl | 3 | 8.0949e-01 ± 1.3140e+00 | 1.8488e-01 ± 1.7268e-01 |\n",
      "| ablation_mild | 3 | 8.6093e-01 ± 1.4293e+00 | 2.3062e-01 ± 2.1622e-01 |\n",
      "| mild_crosskl | 3 | 8.3761e-01 ± 1.2148e+00 | 3.2086e-01 ± 2.7147e-01 |\n",
      "| mild_sophia_onlycrosskl | 3 | 8.2231e-01 ± 1.3833e+00 | 1.8719e-01 ± 1.6789e-01 |\n",
      "| mild_sophia_addcrosskl | 3 | 8.1908e-01 ± 1.3026e+00 | 1.8969e-01 ± 1.7835e-01 |\n",
      "| mild_sophia_ablation | 3 | 8.7155e-01 ± 1.6359e+00 | 1.8328e-01 ± 1.7921e-01 |\n",
      "\n",
      "| ablation_vae | 5 | 7.0876e-01 ± 9.9508e-01 | 1.0172e-01 ± 7.6736e-02 |\n",
      "| vae_crosskl | 5 | 8.8036e-01 ± 1.4217e+00 | 3.3015e-01 ± 2.4543e-01 |\n",
      "| vae_onlycrosskl | 5 | 6.8970e-01 ± 9.4087e-01 | 8.5432e-02 ± 7.1670e-02 |\n",
      "| vae_sophia_onlycrosskl | 5 | 7.6130e-01 ± 1.1069e+00 | 7.2763e-02 ± 5.7594e-02 |\n",
      "| vae_sophia_addcrosskl | 5 | 7.7347e-01 ± 1.1211e+00 | 7.9058e-02 ± 6.2204e-02 |\n",
      "| ablation_mild | 5 | 7.6629e-01 ± 1.0660e+00 | 9.3502e-02 ± 7.5366e-02 |\n",
      "| mild_crosskl | 5 | 8.2818e-01 ± 1.2739e+00 | 3.0760e-01 ± 2.4535e-01 |\n",
      "| mild_sophia_onlycrosskl | 5 | 7.2780e-01 ± 1.0366e+00 | 7.4304e-02 ± 5.7781e-02 |\n",
      "| mild_sophia_addcrosskl | 5 | 7.3063e-01 ± 1.0317e+00 | 6.9145e-02 ± 5.6903e-02 |\n",
      "| mild_sophia_ablation | 5 | 7.5048e-01 ± 1.0796e+00 | 7.4564e-02 ± 5.8476e-02 |\n",
      "\n",
      "| ablation_vae | 8 | 6.9484e-01 ± 9.6848e-01 | 3.7862e-02 ± 3.1341e-02 |\n",
      "| vae_crosskl | 8 | 8.8375e-01 ± 1.4125e+00 | 3.5787e-01 ± 2.5397e-01 |\n",
      "| vae_onlycrosskl | 8 | 6.7312e-01 ± 9.1082e-01 | 4.5782e-02 ± 3.3791e-02 |\n",
      "| vae_sophia_onlycrosskl | 8 | 7.1415e-01 ± 1.1189e+00 | 3.4736e-02 ± 2.2012e-02 |\n",
      "| vae_sophia_addcrosskl | 8 | 6.9836e-01 ± 1.1246e+00 | 3.6916e-02 ± 2.0820e-02 |\n",
      "| ablation_mild | 8 | 6.7108e-01 ± 9.6133e-01 | 3.2600e-02 ± 2.7168e-02 |\n",
      "| mild_crosskl | 8 | 8.7088e-01 ± 1.2077e+00 | 4.0227e-01 ± 2.8925e-01 |\n",
      "| mild_sophia_onlycrosskl | 8 | 6.8773e-01 ± 1.0645e+00 | 3.6437e-02 ± 2.1525e-02 |\n",
      "| mild_sophia_addcrosskl | 8 | 6.7076e-01 ± 1.0725e+00 | 3.3392e-02 ± 1.9890e-02 |\n",
      "| mild_sophia_ablation | 8 | 7.2901e-01 ± 1.1399e+00 | 3.2142e-02 ± 2.1002e-02 |\n",
      "\n",
      "| ablation_vae | 10 | 6.8391e-01 ± 9.4185e-01 | 2.7081e-02 ± 1.9836e-02 |\n",
      "| vae_crosskl | 10 | 7.6653e-01 ± 1.0788e+00 | 3.2315e-01 ± 2.4603e-01 |\n",
      "| vae_onlycrosskl | 10 | 6.5030e-01 ± 9.3792e-01 | 2.7168e-02 ± 1.7195e-02 |\n",
      "| vae_sophia_onlycrosskl | 10 | 7.2432e-01 ± 1.1596e+00 | 3.1299e-02 ± 1.8831e-02 |\n",
      "| vae_sophia_addcrosskl | 10 | 7.2149e-01 ± 1.2061e+00 | 3.0533e-02 ± 2.0243e-02 |\n",
      "| ablation_mild | 10 | 6.5695e-01 ± 9.6006e-01 | 2.3823e-02 ± 1.6922e-02 |\n",
      "| mild_crosskl | 10 | 8.5855e-01 ± 1.1252e+00 | 4.3416e-01 ± 3.1015e-01 |\n",
      "| mild_sophia_onlycrosskl | 10 | 6.6621e-01 ± 1.0662e+00 | 3.1546e-02 ± 1.9416e-02 |\n",
      "| mild_sophia_addcrosskl | 10 | 7.0181e-01 ± 1.1109e+00 | 3.5047e-02 ± 2.0502e-02 |\n",
      "| mild_sophia_ablation | 10 | 6.7520e-01 ± 1.1034e+00 | 3.1964e-02 ± 1.9105e-02 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"| Model | Z Dim | MSE | Recon |\")\n",
    "print(\"|:-----:|:-----:|:----:|:----:|\")\n",
    "for z_dim in [3,5,8,10]:\n",
    "\tfor model_types in [\n",
    "\t\t\t\t\t\t\"ablation_vae\", \n",
    "\t\t\t\t\t\t\"vae_crosskl\", \n",
    "\t\t\t\t\t\t\"vae_onlycrosskl\", \n",
    "\t\t\t\t\t\t\"vae_sophia_onlycrosskl\", \n",
    "\t\t\t\t\t\t\"vae_sophia_addcrosskl\",\n",
    "\t\t\t\t\t\t\"ablation_mild\", \n",
    "\t\t\t\t\t\t\"mild_crosskl\", \n",
    "\t\t\t\t\t\t# \"mild_onlycrosskl\", # Not done with AdamW\n",
    "\t\t\t\t\t\t\"mild_sophia_onlycrosskl\", \n",
    "\t\t\t\t\t\t\"mild_sophia_addcrosskl\",\n",
    "\t\t\t\t\t\t\"mild_sophia_ablation\",\n",
    "\t\t\t\t\t\t# \"vae_ablation\",\n",
    "\t\t\t\t\t\t# \"vae_addcrosskl\",\n",
    "\t\t\t\t\t\t# \"vae_onlycrosskl\",\n",
    "\t\t\t\t\t\t# \"mild_ablation\",\n",
    "\t\t\t\t\t\t# \"mild_addcrosskl\",\n",
    "\t\t\t\t\t\t# \"mild_onlycrosskl\",\n",
    "\t\t\t\t\t]:\n",
    "# if True:\n",
    "# \tif True:\t\n",
    "\t\t# ckpt = 'logs/2023/cross_kld_correct/models/final.pth'\n",
    "\t\tmse_error = []\n",
    "\t\trecon_error = []\n",
    "\t\tfor trial in range(5):\n",
    "\t\t\tckpt = f'logs/2023/{model_types}/z{z_dim}/trial{trial}/models/final.pth' # input()\n",
    "\t\t\tdirname = os.path.dirname(ckpt)\n",
    "\t\t\thyperparams = np.load(os.path.join(dirname,'hyperparams.npz'), allow_pickle=True)\n",
    "\t\t\targs = hyperparams['args'].item()\n",
    "\t\t\tckpt = torch.load(ckpt)\n",
    "\n",
    "\t\t\tmodel = getattr(networks, args.model)(**(hyperparams['ae_config'].item().__dict__)).to(device)\n",
    "\t\t\tmodel.load_state_dict(ckpt['model'])\n",
    "\t\t\tmodel.eval()\n",
    "\t\t\tz_dim = model.latent_dim\n",
    "\t\t\tif model.window_size == 1:\n",
    "\t\t\t\tnb_dim = 4*model.latent_dim\n",
    "\t\t\telse:\n",
    "\t\t\t\tnb_dim = 2*model.latent_dim\n",
    "\t\t\t# dataset = getattr(dataloaders, args.dataset)\n",
    "\t\t\tif model.window_size ==1:\n",
    "\t\t\t\ttrain_iterator = DataLoader(dataloaders.buetepage.SequenceDataset(args.src, train=True), batch_size=1, shuffle=True)\n",
    "\t\t\t\ttest_iterator = DataLoader(dataloaders.buetepage.SequenceDataset(args.src, train=False), batch_size=1, shuffle=True)\n",
    "\t\t\telse:\n",
    "\t\t\t\ttrain_iterator = DataLoader(dataloaders.buetepage.SequenceWindowDataset(args.src, train=True, window_length=model.window_size), batch_size=1, shuffle=True)\n",
    "\t\t\t\ttest_iterator = DataLoader(dataloaders.buetepage.SequenceWindowDataset(args.src, train=False, window_length=model.window_size), batch_size=1, shuffle=True)\n",
    "\t\t\thsmm = ckpt['hsmm']\n",
    "\t\t\t# z_dim = model.latent_dim\n",
    "\t\t\t\n",
    "\t\t\t# for a in range(len(train_iterator.dataset.actidx)):\n",
    "\t\t\t# \ts = train_iterator.dataset.actidx[a]\n",
    "\t\t\t# \tz_encoded = []\n",
    "\t\t\t# \tfor j in range(s[0], s[1]):\n",
    "\t\t\t# \t# for j in np.random.randint(s[0], s[1], 12):\n",
    "\t\t\t# \t\tx, label = train_iterator.dataset[j]\n",
    "\t\t\t# \t\tassert np.all(label == a)\n",
    "\t\t\t# \t\tx = torch.Tensor(x).to(device)\n",
    "\t\t\t# \t\tseq_len, dims = x.shape\n",
    "\t\t\t# \t\tx = torch.concat([x[None, :, :dims//2], x[None, :, dims//2:]]) # x[0] = Agent 1, x[1] = Agent 2\n",
    "\t\t\t\t\t\n",
    "\t\t\t# \t\tzpost_samples = model(x, encode_only=True)\n",
    "\t\t\t# \t\tif model.window_size == 1:\n",
    "\t\t\t# \t\t\tz1_vel = torch.diff(zpost_samples[0], prepend=zpost_samples[0][0:1], dim=0)\n",
    "\t\t\t# \t\t\tz2_vel = torch.diff(zpost_samples[1], prepend=zpost_samples[1][0:1], dim=0)\n",
    "\t\t\t# \t\t\tz_encoded.append(torch.concat([zpost_samples[0], z1_vel, zpost_samples[1], z2_vel], dim=-1).detach().cpu().numpy()) # (num_trajs, seq_len, 2*z_dim)\n",
    "\t\t\t# \t\telse:\n",
    "\t\t\t# \t\t\tz_encoded.append(torch.concat([zpost_samples[0], zpost_samples[1]], dim=-1).detach().cpu().numpy()) # (num_trajs, seq_len, 2*z_dim)\n",
    "\t\t\t# \thsmm[a].init_hmm_kbins(z_encoded)\n",
    "\t\t\t# \thsmm[a].em(z_encoded)\n",
    "\n",
    "\t\t\tpredictions = []\n",
    "\t\t\t# mse_error = []\n",
    "\t\t\t# for a in range(len(train_iterator.dataset.actidx)):\n",
    "\t\t\t# \tmse_error[a] = []\n",
    "\t\t\tfor i, x in enumerate(test_iterator):\n",
    "\t\t\t\tx, label = x\n",
    "\t\t\t\tx = x[0]\n",
    "\t\t\t\tlabel = int(label[0])\n",
    "\t\t\t\tx = torch.Tensor(x).to(device)\n",
    "\t\t\t\tseq_len, dims = x.shape\n",
    "\t\t\t\tx = torch.concat([x[None, :, :dims//2], x[None, :, dims//2:]]) # x[0] = Agent 1, x[1] = Agent 2\n",
    "\t\t\t\t\n",
    "\t\t\t\talpha_hsmm, _, _, _, _ = hsmm[label].compute_messages(marginal=[], sample_size=seq_len)\n",
    "\t\t\t\tif np.any(np.isnan(alpha_hsmm)):\n",
    "\t\t\t\t\tprint('Alpha Nan')\n",
    "\t\t\t\t\talpha_hsmm = forward_variable(hsmm[label], n_step=seq_len)\n",
    "\n",
    "\t\t\t\tseq_alpha = alpha_hsmm.argmax(0)\n",
    "\n",
    "\t\t\t\tx_recon, zpost_samples, zpost_dist = model(x)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\tif model.window_size >1:\n",
    "\t\t\t\t\tz2, sigma2 = hsmm[label].condition(zpost_dist.mean[0].detach().cpu().numpy(), zpost_dist.covariance_matrix[0].detach().cpu().numpy(), dim_in=slice(0, z_dim), dim_out=slice(z_dim, 2*z_dim))\n",
    "\t\t\t\t\t# z2 = hsmm[label].condition(zpost_dist.mean[0].detach().cpu().numpy(), dim_in=slice(0, z_dim), dim_out=slice(z_dim, 2*z_dim))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tz1_vel = torch.diff(zpost_dist.mean[0], prepend=zpost_dist.mean[0][0:1], dim=0)\n",
    "\t\t\t\t\tz2, sigma2 = hsmm[label].condition(torch.concat([zpost_dist.mean[0], z1_vel], dim=-1).detach().cpu().numpy(), zpost_dist.covariance_matrix[0].detach().cpu().numpy(), dim_in=slice(0, 2*z_dim), dim_out=slice(2*z_dim, 3*z_dim))\n",
    "\t\t\t\tx2_gen = model._output(model._decoder(torch.Tensor(z2).to(device)))\n",
    "\t\t\t\t# x1_gen = x_gen[0]\n",
    "\t\t\t\t# x_gen = torch.concat([x1_gen[None], x2_gen[None]])\n",
    "\t\t\t\tx2_recon = x_recon[1].reshape((x[1].shape[0], model.window_size, model.num_joints ,3))\n",
    "\t\t\t\tx2_gen = x2_gen.reshape((x2_gen.shape[0], model.window_size, model.num_joints ,3))\n",
    "\t\t\t\tx2_gt = x[1].reshape((x[1].shape[0], model.window_size, model.num_joints ,3))\n",
    "\t\t\t\t\n",
    "\t\t\t\t# mse_error[label].append(F.mse_loss(x[1], x2_gen, reduction='sum').detach().cpu().numpy())\n",
    "\t\t\t\tmse_i = ((x2_gen - x2_gt)**2).detach().cpu().numpy().sum(-1).sum(-1).sum(-1)\n",
    "\t\t\t\trecon_i = ((x2_recon - x2_gt)**2).detach().cpu().numpy().sum(-1).sum(-1).sum(-1)\n",
    "\t\t\t\tmse_error += mse_i.tolist()\n",
    "\t\t\t\trecon_error += recon_i.tolist()\n",
    "\t\tprint(f\"| {model_types} | {z_dim} | {np.mean(mse_error):.4e} ± {np.std(mse_error):.4e} | {np.mean(recon_error):.4e} ± {np.std(recon_error):.4e} |\")\n",
    "\t\t\t# print(f'MSE: {np.sum(mse_error)}')\n",
    "\tprint('')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
