{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Human VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "import pbdlib as pbd\n",
    "\n",
    "import networks\n",
    "import config\n",
    "from utils import *\n",
    "import dataloaders\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2912188/590562967.py:46: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  z_encoded = np.array(z_encoded)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 4 | 10 | 5.0636e-01 ± 9.5254e-01\n",
      "| 5 | 10 | 5.0876e-01 ± 9.4302e-01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/vignesh/playground/hsmmvae/hsmm_ablation.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvp_dlws/home/vignesh/playground/hsmmvae/hsmm_ablation.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m z_traj \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(z_traj)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvp_dlws/home/vignesh/playground/hsmmvae/hsmm_ablation.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mwindow_size \u001b[39m>\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bvp_dlws/home/vignesh/playground/hsmmvae/hsmm_ablation.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m \tz2_pred, sigma2 \u001b[39m=\u001b[39m hsmm[a]\u001b[39m.\u001b[39;49mcondition(z_traj[:, :z_dim], \u001b[39mNone\u001b[39;49;00m, dim_in\u001b[39m=\u001b[39;49m\u001b[39mslice\u001b[39;49m(\u001b[39m0\u001b[39;49m, z_dim), dim_out\u001b[39m=\u001b[39;49m\u001b[39mslice\u001b[39;49m(z_dim, \u001b[39m2\u001b[39;49m\u001b[39m*\u001b[39;49mz_dim))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvp_dlws/home/vignesh/playground/hsmmvae/hsmm_ablation.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m \t\u001b[39m# z2 = hsmm[label].condition(zpost_dist.mean[0].detach().cpu().numpy(), dim_in=slice(0, z_dim), dim_out=slice(z_dim, 2*z_dim))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvp_dlws/home/vignesh/playground/hsmmvae/hsmm_ablation.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvp_dlws/home/vignesh/playground/hsmmvae/hsmm_ablation.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m \tz1_vel \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdiff(z_traj, prepend\u001b[39m=\u001b[39mz_traj[\u001b[39m0\u001b[39m:\u001b[39m1\u001b[39m, :z_dim], dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pbdlib/hmm.py:473\u001b[0m, in \u001b[0;36mHMM.condition\u001b[0;34m(self, data_in, Sigma_in, dim_in, dim_out, h, return_gmm)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    472\u001b[0m     dim_in_msg \u001b[39m=\u001b[39m dim_in\n\u001b[0;32m--> 473\u001b[0m a, _, _, _, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_messages(data_in, marginal\u001b[39m=\u001b[39;49mdim_in_msg)\n\u001b[1;32m    475\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcondition(data_in, Sigma_in, dim_in, dim_out, h\u001b[39m=\u001b[39ma)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pbdlib/hsmm.py:146\u001b[0m, in \u001b[0;36mHSMM.compute_messages\u001b[0;34m(self, demo, dep, table, marginal, sample_size, p0)\u001b[0m\n\u001b[1;32m    144\u001b[0m \talpha, beta, gamma, zeta, c \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_variable_ts(sample_size, p0\u001b[39m=\u001b[39mp0), \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m \talpha, beta, gamma, zeta, c \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_variable(sample_size, demo, marginal), \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[39mreturn\u001b[39;00m alpha, beta, gamma, zeta, c\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pbdlib/hsmm.py:247\u001b[0m, in \u001b[0;36mHSMM.forward_variable\u001b[0;34m(self, n_step, demo, marginal, dep, p_obs)\u001b[0m\n\u001b[1;32m    244\u001b[0m bmx, ALPHA, S, h[:, \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fwd_init(nbD, p_obs[:, \u001b[39m0\u001b[39m])\n\u001b[1;32m    246\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, n_step):\n\u001b[0;32m--> 247\u001b[0m \tbmx, ALPHA, S, h[:, i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fwd_step(bmx, ALPHA, S, nbD, p_obs[:, i])\n\u001b[1;32m    249\u001b[0m h \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m (np\u001b[39m.\u001b[39msum(h, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m+\u001b[39m \u001b[39m1e-5\u001b[39m)\n\u001b[1;32m    251\u001b[0m \u001b[39mreturn\u001b[39;00m h\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pbdlib/hsmm.py:286\u001b[0m, in \u001b[0;36mHSMM._fwd_step\u001b[0;34m(self, bmx, ALPHA, S, nbD, obs_marginal)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[1;32m    276\u001b[0m \u001b[39m:param bmx:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[39m:return:\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    283\u001b[0m Btmp \u001b[39m=\u001b[39m obs_marginal\n\u001b[1;32m    285\u001b[0m ALPHA \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((S[:, [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPd[:, \u001b[39m0\u001b[39m:nbD \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m bmx[:, [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]] \u001b[39m*\u001b[39m ALPHA[:, \u001b[39m1\u001b[39m:nbD],\n\u001b[0;32m--> 286\u001b[0m \t\t\t\t\t\tS[:, [\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]] \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mPd[:, [nbD \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m]]), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    288\u001b[0m r \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(Btmp\u001b[39m.\u001b[39mT, np\u001b[39m.\u001b[39msum(ALPHA, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)) \u001b[39m+\u001b[39m \u001b[39m1e-8\u001b[39m\n\u001b[1;32m    289\u001b[0m bmx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((bmx, Btmp[:, \u001b[39mNone\u001b[39;00m] \u001b[39m/\u001b[39m r), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_types = \"ablation_vae\"\n",
    "z_dims = [10]\n",
    "z_trajs = [[], [], [], []]\n",
    "\n",
    "for i in range(len(z_dims)):\n",
    "\tz_dim = z_dims[i]\n",
    "\tckpt = f'logs/2023/{model_types}/z{z_dim}/trial0/models/final.pth' # input()\n",
    "\tdirname = os.path.dirname(ckpt)\n",
    "\thyperparams = np.load(os.path.join(dirname,'hyperparams.npz'), allow_pickle=True)\n",
    "\targs = hyperparams['args'].item()\n",
    "\tckpt = torch.load(ckpt)\n",
    "\n",
    "\tmodel = getattr(networks, args.model)(**(hyperparams['ae_config'].item().__dict__)).to(device)\n",
    "\tmodel.load_state_dict(ckpt['model'])\n",
    "\tmodel.eval()\n",
    "\tz_dim = model.latent_dim\n",
    "\tif model.window_size == 1:\n",
    "\t\tnb_dim = 4*model.latent_dim\n",
    "\telse:\n",
    "\t\tnb_dim = 2*model.latent_dim\n",
    "\t# dataset = getattr(dataloaders, args.dataset)\n",
    "\tif model.window_size ==1:\n",
    "\t\ttrain_iterator = DataLoader(dataloaders.buetepage.SequenceDataset(args.src, train=True), batch_size=1, shuffle=True)\n",
    "\t\ttest_iterator = DataLoader(dataloaders.buetepage.SequenceDataset(args.src, train=False), batch_size=1, shuffle=True)\n",
    "\telse:\n",
    "\t\ttrain_iterator = DataLoader(dataloaders.buetepage.SequenceWindowDataset(args.src, train=True, window_length=model.window_size), batch_size=1, shuffle=True)\n",
    "\t\ttest_iterator = DataLoader(dataloaders.buetepage.SequenceWindowDataset(args.src, train=False, window_length=model.window_size), batch_size=1, shuffle=True)\n",
    "\tfor a in range(len(train_iterator.dataset.actidx)):\n",
    "\t\ts = train_iterator.dataset.actidx[a]\n",
    "\t\tz_encoded = []\n",
    "\t\tfor j in range(s[0], s[1]):\n",
    "\t\t# for j in np.random.randint(s[0], s[1], 12):\n",
    "\t\t\tx, label = train_iterator.dataset[j]\n",
    "\t\t\tassert np.all(label == a)\n",
    "\t\t\tx = torch.Tensor(x).to(device)\n",
    "\t\t\tseq_len, dims = x.shape\n",
    "\t\t\tx = torch.concat([x[None, :, :dims//2], x[None, :, dims//2:]]) # x[0] = Agent 1, x[1] = Agent 2\n",
    "\t\t\t\n",
    "\t\t\tzpost_samples = model(x, encode_only=True)\n",
    "\t\t\tif model.window_size == 1:\n",
    "\t\t\t\tz1_vel = torch.diff(zpost_samples[0], prepend=zpost_samples[0][0:1], dim=0)\n",
    "\t\t\t\tz2_vel = torch.diff(zpost_samples[1], prepend=zpost_samples[1][0:1], dim=0)\n",
    "\t\t\t\tz_encoded.append(torch.concat([zpost_samples[0], z1_vel, zpost_samples[1], z2_vel], dim=-1).detach().cpu().numpy()) # (num_trajs, seq_len, 2*z_dim)\n",
    "\t\t\telse:\n",
    "\t\t\t\tz_encoded.append(torch.concat([zpost_samples[0], zpost_samples[1]], dim=-1).detach().cpu().numpy()) # (num_trajs, seq_len, 2*z_dim)\n",
    "\t\tz_encoded = np.array(z_encoded)\n",
    "\t\tz_trajs[i].append(z_encoded)\n",
    "\tfor nb_states in [4,5,8,10]:\n",
    "\t\thsmm = [pbd.HSMM(nb_dim=nb_dim, nb_states=nb_states) for a in range(len(train_iterator.dataset.actidx))]\n",
    "\t\t\n",
    "\t\tmse_error = []\n",
    "\t\tfor a in range(len(train_iterator.dataset.actidx)):\n",
    "\t\t\ttrain_idx = np.random.choice(np.arange(len(z_trajs[i][a])),10,False).astype(int)\n",
    "\t\t\thsmm[a].init_hmm_kbins(z_trajs[i][a][train_idx])\n",
    "\t\t\thsmm[a].em(z_trajs[i][a][train_idx], nb_max_steps=60)\n",
    "\n",
    "\t\t# predictions = []\n",
    "\t\t# for a in range(len(train_iterator.dataset.actidx)):\n",
    "\t\t\tfor z_traj in z_trajs[i][a]:\n",
    "\t\t\t\tz_traj = np.array(z_traj)\n",
    "\t\t\t\tif model.window_size >1:\n",
    "\t\t\t\t\tz2_pred, sigma2 = hsmm[a].condition(z_traj[:, :z_dim], None, dim_in=slice(0, z_dim), dim_out=slice(z_dim, 2*z_dim))\n",
    "\t\t\t\t\t# z2 = hsmm[label].condition(zpost_dist.mean[0].detach().cpu().numpy(), dim_in=slice(0, z_dim), dim_out=slice(z_dim, 2*z_dim))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tz1_vel = np.diff(z_traj, prepend=z_traj[0:1, :z_dim], axis=0)\n",
    "\t\t\t\t\tz2_pred, sigma2 = hsmm[a].condition(torch.concat([z_traj[:, :z_dim], z1_vel], dim=-1), None, dim_in=slice(0, 2*z_dim), dim_out=slice(2*z_dim, 3*z_dim))\n",
    "\t\t\t\t\n",
    "\t\t\t\tmse_i = ((z_traj[:, z_dim:] - z2_pred)**2).sum(-1)\n",
    "\t\t\t\tmse_error += mse_i.tolist()\n",
    "\t\t\t\t# recon_error += recon_i.tolist()\n",
    "\t\tprint(f\"| {nb_states} | {z_dim} | {np.mean(mse_error):.4e} ± {np.std(mse_error):.4e}\")\n",
    "\t\t\t\t# print(f'MSE: {np.sum(mse_error)}')\n",
    "\tprint('')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
